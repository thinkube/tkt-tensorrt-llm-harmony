apiVersion: thinkube.io/v1
kind: TemplateManifest
metadata:
  name: tkt-tensorrt-llm
  title: TensorRT-LLM Inference Server
  description: NVIDIA TensorRT-LLM optimized inference with NVFP4 support for Blackwell (DGX Spark GB10)
  version: 1.0.0
  author: Thinkube Team
  tags: ["ai", "llm", "tensorrt-llm", "nvidia", "gradio", "inference", "text-generation", "gpu", "blackwell", "nvfp4"]

parameters:
  - name: model_id
    type: choice
    description: Select pre-quantized model from NVIDIA (FP4/FP8/MXFP4 for Blackwell)
    default: nvidia/Llama-3.1-8B-Instruct-FP4
    choices:
      - openai/gpt-oss-20b
      - openai/gpt-oss-120b
      - nvidia/Llama-3.1-8B-Instruct-FP8
      - nvidia/Llama-3.1-8B-Instruct-FP4
      - nvidia/Llama-3.3-70B-Instruct-FP4
      - nvidia/Qwen3-8B-FP8
      - nvidia/Qwen3-8B-FP4
      - nvidia/Qwen3-14B-FP8
      - nvidia/Qwen3-14B-FP4
      - nvidia/Qwen3-32B-FP4
      - nvidia/Phi-4-multimodal-instruct-FP8
      - nvidia/Phi-4-multimodal-instruct-FP4
      - nvidia/Phi-4-reasoning-plus-FP8
      - nvidia/Phi-4-reasoning-plus-FP4
      - nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-FP8
      - nvidia/Qwen3-30B-A3B-FP4
      - nvidia/Qwen2.5-VL-7B-Instruct-FP8
      - nvidia/Qwen2.5-VL-7B-Instruct-FP4
      - nvidia/Llama-4-Scout-17B-16E-Instruct-FP4
      - nvidia/Qwen3-235B-A22B-FP4

secrets:
  - name: HF_TOKEN
    description: Hugging Face API token for accessing gated models
    required: true
    
